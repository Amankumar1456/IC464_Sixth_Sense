## SIH2020_IC464_Sixth_Sense_GitRepository_MLRIT
### Table Of Content
* Introduction
* Prerequisites
* Installation Guide
* Supported Platforms
* Future Development and Direction
## Introduction üóíÔ∏è
The goal of this Project is to detect sign-language gestures performed by the user and display them as text on the screen(Real-time-caption). In order to achieve this, we are using the [MediaPipe](https://google.github.io/mediapipe/) framework for hand-detection and hand-tracking along with our Sign-Language-Detection Calculator to classify the sign-language gestures enacted by the user.We have not gone the traditional way of training the model on thousands of images instead we have appplied Landmark Detection.

## Solution üìêArchitectural Visualization

![Architecture](/Images_Readme/architecture.JPG)

## Cross-platform ML solutions for Sign-to-Text made Simple 

The sign processing machine currently is supprted by the following devices:

![Desktop_img](/Images_Readme/dekstop.png)                                                               | ![Android_img](/Images_Readme/tutorial.png)
:------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------:
**Desktop**: *You can experience the seemless performance right infront of your laptop screen.* | **Android**: *Use the tutorial app to understand the Sign language with user-freindly Interface,have a look below.*

## Implimentation of Machine (In-Action)

Sign Language-to-Text                                                                                                                 | Learn Sign Language                                                                                                       | 
:----------------------------------------------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------------: |
[![Sign_to_Text](/Images_Readme/sign-text.gif)]| [![Learn_Sign](/Images_Readme/learn.gif)] | 

## Future Development and Direction
* Scale the application for Commonly used Video Conferencing applications.
* Adding Voice feature so that Sign language to Voice is possible.
* Building the Solution on Augmented Reality to view the text in open spacec.
* Add query fullfilment for better usage of technolgy by the Deaf and Mute section of the society.
